Time complexity big O notation describes how your programs runtime and memory usage scales as the input data scales.

![[Pasted image 20241206140749.png]]

In this graph you can see how long your program will take to run in regards to how much input data you give it.
The pink section is where thing start to slow down pretty quickly as the input data increases.
And the opposite goes for the other half.

Ideally your program just completes one instruction and terminates which is O(1).
Or as I like to think of it O of one instruction per element.
Another example O(n) or in my words, O of x number of instructions linear to the elements.
And for the pink section, the more elements more instructions and some more every increase in data.

